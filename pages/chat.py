import os
import json
from dotenv import load_dotenv
import streamlit as st
from langchain_openai import ChatOpenAI
from langchain.schema import SystemMessage, HumanMessage, AIMessage


# List of pages
pages = {
    "ğŸ¡ choose the page": None,
    "ğŸ  home": "home.py",
    "ğŸ” search people" : "pages/people_list.py",
    "ğŸ§‘ğŸ‘§ friends": "./pages/friends_list.py",
    "ğŸš§ logout": "pages/logout.py",
}

# Dropdown to select the page
selected_page = st.selectbox("Select a page:", list(pages.keys()))

    # í˜ì´ì§€ ì´ë™ ì²˜ë¦¬
if pages[selected_page]:  # ì„ íƒëœ í˜ì´ì§€ê°€ Noneì´ ì•„ë‹ ê²½ìš°
    st.switch_page(pages[selected_page])  # switch_pageë¡œ ì´ë™

# ì‚¬ìš©ì ë°ì´í„°ë² ì´ìŠ¤ JSON íŒŒì¼ ê²½ë¡œ
USER_DATA_FILE = "user_data.json"
def load_user_data_from_json(file_path=USER_DATA_FILE):
    if os.path.exists(file_path):
        with open(file_path, "r", encoding="utf-8") as f:
            return json.load(f)
    return []

selected_person_name=st.session_state["selected_person_name"]
selected_person_email=st.session_state["selected_person_email"]
print(f"í˜„ì¬ ì„ íƒí•œ ì‚¬ëŒ ë©”ì¼: {selected_person_email}")
user_chat_history={}
user_db=load_user_data_from_json(file_path=USER_DATA_FILE)
for user in user_db:
    if user["email"] == selected_person_email:
        user_chat_history=user["chat_history"]
    else:
        print(f"í•´ë‹¹ ìœ ì €ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
# .env íŒŒì¼ ë¡œë“œ
load_dotenv()
default_openai_api_key = os.getenv("OPENAI_API_KEY")

# OpenAI LLM ì´ˆê¸°í™”
llm = ChatOpenAI(model="gpt-4o", temperature=0)

# user_chat_historyì—ì„œ 'role': 'system'ì¸ í•­ëª©ì„ ì œê±°
filtered_history = [entry for entry in user_chat_history if entry['role'] != 'system']

# ê²°ê³¼ ì¶œë ¥
print("filtered_history", filtered_history)

# í”„ë¡¬í”„íŠ¸ ì •ì˜
initial_prompt = SystemMessage(content=f"""
You are an AI conversational assistant tasked with perfectly mirroring the User's tone, style, and interests as demonstrated in the example below. Your primary goal is to craft responses that closely replicate the User's tone and word choice, ensuring the use of key phrases, terms, and expressions found in the User's dialogue (role: "user"). If the User introduces a topic that does not align with the example, you must infer an appropriate response while maintaining the overall tone and style.

Key Instructions:
1. Tone and Style
   - replicate the Userâ€™s tone, speech patterns, and phrasing as shown in the example's User dialogue (role: "user").
   - Use the same key terms, vivid expressions, and sentence structure as demonstrated in the User's dialogue.
   - Avoid overgeneralizing or neutralizing your tone. Responses must feel intense, dramatic, or symbolic to match the example.

2. Contextual Engagement
   - Respond directly to the Userâ€™s input by using the style and vocabulary from the example dialogues.
   - If the User introduces a question or topic that completely deviates from the example, infer an appropriate response while maintaining the tone, structure, and word choice that align with the example dialogue.
   - For unfamiliar topics, adapt the response creatively to preserve the example tone and ensure logical flow.

3. Exact Replication with Flexibility for New Topics
   - For topics aligned with the example dialogue, prioritize replicating the Userâ€™s expressions, tone, and structure precisely.
   - When new or unexpected topics arise, answer them flexibly while ensuring stylistic consistency with the User's tone and speech patterns.

4. Relevance and Creativity
   - Ensure responses remain relevant to the User's input and are anchored in the example style and tone.
   - Avoid repetitive phrases by varying wording while staying consistent with the User's dialogue mannerisms.

5. Natural Dialogue Flow
   - Maintain logical flow in the conversation, ensuring transitions between topics are seamless and stylistically coherent.
   - Even when inferring answers for unfamiliar topics, responses must feel natural and aligned with the Userâ€™s tone and mannerisms.

6. Termination and Boundaries
   - If the User explicitly asks you to stop, immediately end the conversation in Korean without further prompts.
   - Once the conversation is complete, naturally conclude with the following phrase:
     "ê°ì‚¬í•©ë‹ˆë‹¤. ê³ ê°ë‹˜ê³¼ì˜ ëŒ€í™”ê°€ ì¦ê±°ì› ìŠµë‹ˆë‹¤. ì¢‹ì€ í•˜ë£¨ ë³´ë‚´ì„¸ìš”!"

### Starting the Conversation
Begin the conversation by asking the User what they want to discuss, using the tone and style of the User dialogue (role: "user") in the example provided. For instance:
"ëŒ€í™”ë¥¼ ì‹œì‘í•´ë³´ì„¸ìš”. (ì˜ˆì‹œ: ì–¸ì–´ ê³µë¶€ì˜ ì´ìœ , ìµœê·¼ ê´€ì‹¬ì‚¬, ìŠ¤íŠ¸ë ˆìŠ¤ í‘¸ëŠ” ë²• ë“±)"

### Example Interaction:
{filtered_history}

Emphasis:
Your task is to prioritize the User's tone, expressions, and style in every response, mirroring the example dialogue provided. Use the specific language, structure, and emotional intensity found in the Userâ€™s input as your primary guide. For topics that deviate from the example, infer a response while maintaining stylistic consistency.
""")

# Streamlit ìƒíƒœ ì´ˆê¸°í™”
if "friend_chat_history" not in st.session_state:
    st.session_state.friend_chat_history = []
if "friend_conversation_done" not in st.session_state:
    st.session_state.friend_conversation_done = False

# ë©”ì‹œì§€ ì¶”ê°€ í•¨ìˆ˜
def add_message(role, content):
    """role: 'user' ë˜ëŠ” 'assistant'"""
    st.session_state.friend_chat_history.append({"role": role, "content": content})

# ëŒ€í™” ê¸°ë¡ì„ JSON íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ” í•¨ìˆ˜
def save_chat_history_to_json(file_path="friend_chat_history.json"):
    with open(file_path, "w", encoding="utf-8") as f:
        json.dump(st.session_state.friend_chat_history, f, ensure_ascii=False, indent=4)

# Streamlit UI êµ¬ì„±
st.title(f"ğŸ’¬ {selected_person_name}ë‹˜ê»˜ ë§ì„ ê±¸ì–´ë³´ì„¸ìš”.")
st.caption("ğŸš€ ì´ 20ë²ˆ ë°œí™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")


# ì´ˆê¸° ë©”ì‹œì§€ ì²˜ë¦¬
if not st.session_state.friend_chat_history:
    add_message("system", initial_prompt.content)
    try:
        # ì´ˆê¸° ë©”ì‹œì§€ì— ëŒ€í•œ LLM ì‘ë‹µ ìƒì„±
        llm_response = llm([SystemMessage(content=initial_prompt.content)])
        add_message("assistant", llm_response.content)
    except Exception as e:
        add_message("assistant", f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

# ê¸°ì¡´ ë©”ì‹œì§€ ë Œë”ë§
for msg in st.session_state.friend_chat_history:
    if msg["role"] == "user":
        st.chat_message("user").write(msg["content"])
    elif msg["role"] == "assistant":
        st.chat_message("assistant").write(msg["content"])

if not st.session_state.friend_conversation_done:  # ëŒ€í™” ì¢…ë£Œ ìƒíƒœê°€ ì•„ë‹ ë•Œë§Œ ì…ë ¥ í—ˆìš©
    # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
    if user_input := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”:"):
        add_message("user", user_input)
        st.chat_message("user").write(user_input)

        try:
            # ëŒ€í™” ë‚´ì—­ì„ ê¸°ë°˜ìœ¼ë¡œ ë©”ì‹œì§€ ìƒì„±
            messages = [
                SystemMessage(content=initial_prompt.content)
            ] + [
                HumanMessage(content=msg["content"]) if msg["role"] == "user" else AIMessage(content=msg["content"])
                for msg in st.session_state.friend_chat_history if msg["role"] != "system"
            ]

            # LLM í˜¸ì¶œ
            llm_response = llm(messages)
            response_content = llm_response.content

            # ëª¨ë¸ ì‘ë‹µ ì¶”ê°€
            add_message("assistant", response_content)
            st.chat_message("assistant").write(response_content)

            # ëŒ€í™” ì¢…ë£Œ ë©”ì‹œì§€ í™•ì¸
            if "ì¦ê±°ì› ìŠµë‹ˆë‹¤" in response_content:
                st.session_state.friend_conversation_done = True
            save_chat_history_to_json()
            print("ëŒ€í™” ê¸°ë¡ì´ friend_chat_history.json íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")


        except Exception as e:
            response_content = f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
            add_message("assistant", response_content)
            st.chat_message("assistant").write(response_content)

# ë””ë²„ê¹…: ìƒíƒœ ì¶œë ¥
print("=======íšŒì›ê°€ì… ìµœì¢… ëŒ€í™” ê¸°ë¡ =======")
for message in st.session_state.friend_chat_history:
    print(f"{message['role']}: {message['content']}")
print("=========================")

user_data_path="user_data.json"
# ëŒ€í™” ì¢…ë£Œ í›„ íšŒì›ê°€ì… ì™„ë£Œ ë²„íŠ¼ í‘œì‹œ
if st.session_state.friend_conversation_done:
    
    st.success("ëŒ€í™”ê°€ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì¹œêµ¬ ëª©ë¡ì— ì¶”ê°€í•˜ì‹œê² ìŠµë‹ˆê¹Œ?")
    if st.button("ì¹œêµ¬ ì¶”ê°€"):
        # íŒŒì¼ ì½ê¸°
        with open(user_data_path, "r") as file:
            user_data = json.load(file)

        # ì´ë©”ì¼ê³¼ ì¼ì¹˜í•˜ëŠ” ì‚¬ìš©ì ì°¾ê¸°
        for user in user_data:
                # ì„ íƒëœ ì¹œêµ¬ ì¶”ê°€
            if "friends" not in user:
                user["friends"] = {}  # friends í‚¤ê°€ ì—†ìœ¼ë©´ ë”•ì…”ë„ˆë¦¬ë¡œ ìƒì„±

            selected_person_email = st.session_state.get("selected_person_email")
            selected_person_name = st.session_state.get("selected_person_name")

            # ì¹œêµ¬ ì¶”ê°€ ì¡°ê±´ í™•ì¸
            if selected_person_email and selected_person_email not in user["friends"]:
                user["friends"][selected_person_email] = selected_person_name


        # íŒŒì¼ ì €ì¥
        with open(user_data_path, "w") as file:
            json.dump(user_data, file, ensure_ascii=False, indent=4)

        print(f"{selected_person_name}ë‹˜ì´ ì¹œêµ¬ ëª©ë¡ì— ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.")
        st.session_state.friend_conversation_done=False
        st.session_state.friend_chat_history = []
        st.switch_page("pages/friends_list.py")
    if st.button("ëª©ë¡ ëŒì•„ê°€ê¸°"):
        st.session_state.friend_chat_history = []
        st.session_state.friend_conversation_done=False
        st.switch_page("pages/people_list.py")
